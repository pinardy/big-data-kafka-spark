{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Safety Category: Models\n",
    "\n",
    "In this notebook, several models are tested on the preprocessed training data.\n",
    "\n",
    "**Models:**\n",
    "\n",
    "- Random Forest\n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Neural Network"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading the data ##",
   "id": "3ba10ef922444b11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:21.908333Z",
     "start_time": "2025-03-19T01:30:14.925198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, LinearSVC, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"ModelComparison\").getOrCreate()\n",
    "\n",
    "# Load CSV dataset\n",
    "data_path = \"data/safety_dataset_filtered.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show data schema\n",
    "df.printSchema()"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bookingID: long (nullable = true)\n",
      " |-- Speed_perc70: double (nullable = true)\n",
      " |-- acceleration_x_min: double (nullable = true)\n",
      " |-- acceleration_z_std: double (nullable = true)\n",
      " |-- Bearing_std: double (nullable = true)\n",
      " |-- acceleration_x_std: double (nullable = true)\n",
      " |-- Speed_std: double (nullable = true)\n",
      " |-- acceleration_y_std: double (nullable = true)\n",
      " |-- acceleration_z_max: double (nullable = true)\n",
      " |-- Speed_max: double (nullable = true)\n",
      " |-- time: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing the data ##",
   "id": "e460c46a77815b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:21.996857Z",
     "start_time": "2025-03-19T01:30:21.925339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop non-feature columns\n",
    "df = df.drop(\"bookingID\")\n",
    "\n",
    "# Ensure 'label' is integer type\n",
    "df = df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "\n",
    "feature_cols = [col_name for col_name in df.columns if col_name != \"label\"]\n",
    "\n",
    "feature_cols"
   ],
   "id": "a3b1ae4de32f3ea2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Speed_perc70',\n",
       " 'acceleration_x_min',\n",
       " 'acceleration_z_std',\n",
       " 'Bearing_std',\n",
       " 'acceleration_x_std',\n",
       " 'Speed_std',\n",
       " 'acceleration_y_std',\n",
       " 'acceleration_z_max',\n",
       " 'Speed_max',\n",
       " 'time']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:23.560577Z",
     "start_time": "2025-03-19T01:30:22.335779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert features into a single feature vector\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=False)\n",
    "df = scaler.fit(df).transform(df)\n",
    "\n",
    "# Select only the 'scaled_features' and 'label' columns\n",
    "df = df.select(\"scaled_features\", \"label\")\n",
    "df = df.withColumnRenamed(\"scaled_features\", \"features\")\n",
    "\n",
    "# Show sample processed data\n",
    "df.show(5, truncate=False)"
   ],
   "id": "4b2a4f2f9212cae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                                                         |label|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[2.46632374490225,-1.7137477662481138,1.721000516645763,4.590215978024872,2.0611283187167313,3.8006332049649876,0.9211031805473977,0.456982800746409,4.317393682544466,1.1572045267372614E-4]    |0    |\n",
      "|[2.0649761468201704,-1.955052600432529,1.2882197597306149,3.1918143431744297,1.652765068822707,3.7264367296228014,0.7685017022083639,0.29192196676784254,4.117208894890124,7.53020440935386E-5]  |1    |\n",
      "|[0.8584829532397708,-1.085194114232993,1.5381663293821843,4.238047435347158,1.6803770207897677,1.5296465477426933,0.7278805031243282,0.45580286657568975,1.7612108370962327,6.008141815973824E-5]|1    |\n",
      "|[1.4001805699788588,-1.0469049660986676,1.1755101780864488,2.531599447473731,1.170951514199267,2.95391714946557,0.8607769292448503,0.05840845496094556,3.721683119032532,7.96716017778832E-5]    |1    |\n",
      "|[1.3240308529968003,-1.5897527034106198,1.420758562715812,3.9734895557704863,1.8351402245098285,2.805555438392337,0.8883937362271659,1.5721895617666843,3.0847248485882,7.96716017778832E-5]     |0    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split Data for Training and Testing ##",
   "id": "69294912fa08c0a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:24.448938Z",
     "start_time": "2025-03-19T01:30:23.577020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data into train (80%) and test (20%)\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Show dataset sizes\n",
    "print(f\"Training Data: {train_df.count()} rows\")\n",
    "print(f\"Test Data: {test_df.count()} rows\")"
   ],
   "id": "74053ce6822400c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 16052 rows\n",
      "Test Data: 3948 rows\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train the Models ##\n",
    "Each model is trained with train_df, and then predictions are made on test_df."
   ],
   "id": "73ae673bcb20833c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Train Random Forest**",
   "id": "f953141c04017513"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:27.640930Z",
     "start_time": "2025-03-19T01:30:24.453945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50)\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_preds = rf_model.transform(test_df)"
   ],
   "id": "e2c9f90b37298928",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Train Logistic Regression**",
   "id": "deb2d8103470de61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:29.872432Z",
     "start_time": "2025-03-19T01:30:27.654333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_df)\n",
    "lr_preds = lr_model.transform(test_df)"
   ],
   "id": "a2e27d69f3657e6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Train Support Vector Machine (SVM)**",
   "id": "590abb59487258e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:30.801006Z",
     "start_time": "2025-03-19T01:30:29.881268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "svm_model = svm.fit(train_df)\n",
    "svm_preds = svm_model.transform(test_df)"
   ],
   "id": "76d33dfaadd0d7b3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Train Neural Network**\n",
    "- The input layer size is the **number of features**.\n",
    "- The output layer size is the **number of unique labels**."
   ],
   "id": "5f2d35f2928cfb47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:34.506608Z",
     "start_time": "2025-03-19T01:30:30.810648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_features = len(feature_cols)\n",
    "num_classes = df.select(\"label\").distinct().count()\n",
    "\n",
    "nn = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    layers=[num_features, 16, 8, num_classes],  # Example: 3 hidden layers\n",
    "    blockSize=128,\n",
    "    maxIter=100\n",
    ")\n",
    "\n",
    "nn_model = nn.fit(train_df)\n",
    "nn_preds = nn_model.transform(test_df)"
   ],
   "id": "459dd10b48e7fe1e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate Models ##\n",
    "To check which model performs best, we evaluate accuracy and F1-score."
   ],
   "id": "bf7b92a9cd31c99c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T01:30:36.111790Z",
     "start_time": "2025-03-19T01:30:34.518047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize evaluators\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"f1\")\n",
    "\n",
    "# Store models and predictions\n",
    "models = {\n",
    "    \"Random Forest\": rf_preds,\n",
    "    \"Logistic Regression\": lr_preds,\n",
    "    \"SVM\": svm_preds,\n",
    "    \"Neural Network\": nn_preds\n",
    "}\n",
    "\n",
    "# Compute accuracy and F1-score for each model\n",
    "for name, preds in models.items():\n",
    "    acc = evaluator_acc.evaluate(preds)\n",
    "    f1 = evaluator_f1.evaluate(preds)\n",
    "    print(f\"{name}: Accuracy = {acc:.4f}, F1-score = {f1:.4f}\")"
   ],
   "id": "6e7e87d67bfa0475",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy = 0.7791, F1-score = 0.7161\n",
      "Logistic Regression: Accuracy = 0.7629, F1-score = 0.6800\n",
      "SVM: Accuracy = 0.7611, F1-score = 0.6638\n",
      "Neural Network: Accuracy = 0.7647, F1-score = 0.6787\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion ##\n",
    "Based on the evaluate results, we choose the **Random Forest** model which performs the best."
   ],
   "id": "2486226e11c96a59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
