services:
  consumer:
    image: consumer:latest
    container_name: consumer
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: streaming
      POSTGRES_DB: postgres
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
    depends_on:
      kafka:
        condition: service_healthy

  producer:
    image: producer:latest
    container_name: producer
    depends_on:
      - consumer
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: streaming
    ports:
      - "8001:8000"

  backend:
    image: backend:latest
    container_name: backend
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
    ports:
      - "8000:8000"

  frontend:
    image: frontend:latest
    container_name: frontend
    ports:
      - "3000:80"

  spark-master:
    image: batch-processing:latest
    container_name: spark-master
    environment:
      - JAVA_HOME=/opt/bitnami/java
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_UI_PORT=8080
      - SPARK_RPC_AUTHENTICATION_ENABLED=false
      - SPARK_LOCAL_DIRS=/tmp/spark-temp
    ports:
      - "8089:8080" # Spark UI
      - "7077:7077" # Spark Master port
    volumes:
      - spark-data:/opt/bitnami/spark
      - ./batch-processing:/scripts
      - ./data:/data

  spark-worker:
    image: batch-processing:latest
    container_name: spark-worker
    environment:
      - JAVA_HOME=/opt/bitnami/java
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_LOCAL_DIRS=/tmp/spark-temp
    depends_on:
      - spark-master
    volumes:
      - spark-data:/opt/bitnami/spark
      - ./batch-processing:/scripts
      - ./data:/data

  spark-submit:
    image: batch-processing:latest
    container_name: spark-submit
    depends_on:
      spark-master:
        condition: service_started
      kafka:
        condition: service_healthy
    environment:
      - JAVA_HOME=/opt/bitnami/java
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512m
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_LOCAL_DIRS=/tmp/spark-temp
      - MINIO_ADDRESS=minio
      - MINIO_PORT=9000
      - MINIO_USER=miniouser
      - MINIO_PASSWORD=miniopassword
      - POSTGRES_ADDRESS=postgres_db
      - POSTGRES_PORT=5432
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=password
      - KAFKA_BROKER=kafka:9092
      - KAFKA_TOPIC=batch_processing

    entrypoint: [
        "/bin/bash",
        "-c",
        "
        echo 'Running Batch Processing... [CLOSED]';
        # spark-submit --jars /tmp/postgresql-*.jar /scripts/batch-processing.py;

        echo 'Sleeping for 24 hours... [INCOMPLETE]';
        # sleep 86400;  # Wait 24 hours before next batch

        echo 'Running Model Training... [TEST]';
        # spark-submit --jars /tmp/postgresql-*.jar /scripts/model-training.py;
        ",
      ]
    volumes:
      - spark-data:/opt/bitnami/spark
      - ./batch-processing:/scripts
      - ./data:/data

  streaming-handler:
    image: sparkml:latest
    container_name: streaming-handler
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - JAVA_HOME=/opt/bitnami/java
      - KAFKA_BROKER=kafka:9092
      - KAFKA_TOPIC_INPUT=streaming
      - KAFKA_TOPIC_OUTPUT=predictions
      - POSTGRES_ADDRESS=postgres_db
      - POSTGRES_PORT=5432
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=password
      - MINIO_ADDRESS=minio
      - MINIO_PORT=9000
      - MINIO_USER=miniouser
      - MINIO_PASSWORD=miniopassword
    entrypoint: [
        "/bin/bash",
        "-c",
        "
        echo 'Starting Streaming Data Handler...';
        python /scripts/streaming-data-handling.py
        ",
      ]
    volumes:
      - ./sparkml:/scripts

volumes:
  minio_data:
    driver: local
  postgres_data:
  spark-data:
