{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Training #\n",
    "\n",
    "Based on the comparison results, we choose to use Random Forest model to train our model."
   ],
   "id": "7e0497516c9e4a12"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-19T04:42:02.567195Z",
     "start_time": "2025-03-19T04:41:55.079509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ModelTraining\").getOrCreate()\n",
    "\n",
    "data_path = \"data/safety_dataset_filtered.csv\"\n",
    "# data_path = \"data/safety_dataset_new.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "\n",
    "df.groupBy(\"label\").count().show()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 4991|\n",
      "|    0|15009|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:42:04.250512Z",
     "start_time": "2025-03-19T04:42:02.603227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop non-feature columns\n",
    "df = df.drop(\"bookingID\")\n",
    "\n",
    "# Ensure 'label' is integer type\n",
    "df = df.withColumn(\"label\", col(\"label\").cast(\"integer\"))\n",
    "\n",
    "feature_cols = [col_name for col_name in df.columns if col_name != \"label\"]\n",
    "print(feature_cols)\n",
    "\n",
    "# Convert features into a single feature vector\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=False)\n",
    "df = scaler.fit(df).transform(df)\n",
    "\n",
    "# Select only the 'scaled_features' and 'label' columns\n",
    "df = df.select(\"scaled_features\", \"label\")\n",
    "df = df.withColumnRenamed(\"scaled_features\", \"features\")\n",
    "\n",
    "# Split data into train (80%) and test (20%)\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Show dataset sizes\n",
    "print(f\"Training Data: {train_df.count()} rows\")\n",
    "print(f\"Test Data: {test_df.count()} rows\")"
   ],
   "id": "604986c8d70cf50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed_perc70', 'acceleration_x_min', 'acceleration_z_std', 'Bearing_std', 'acceleration_x_std', 'Speed_std', 'acceleration_y_std', 'acceleration_z_max', 'Speed_max', 'time']\n",
      "Training Data: 16052 rows\n",
      "Test Data: 3948 rows\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:42:05.066308Z",
     "start_time": "2025-03-19T04:42:04.575473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "majority_count = train_df.filter(train_df.label == 0).count()\n",
    "minority_count = train_df.filter(train_df.label == 1).count()\n",
    "\n",
    "ratio = majority_count / minority_count\n",
    "print(f\"Class 0: {majority_count}, Class 1: {minority_count}, Ratio: {ratio:.2f}\")"
   ],
   "id": "8a9bc2d1a150ab3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 12024, Class 1: 4028, Ratio: 2.99\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:42:08.383988Z",
     "start_time": "2025-03-19T04:42:05.073341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "rf_model = rf.fit(train_df)\n",
    "rf_preds = rf_model.transform(test_df)"
   ],
   "id": "856a8497239ffe75",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:42:09.761501Z",
     "start_time": "2025-03-19T04:42:08.404561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model_evaluator(preds_model):\n",
    "    # Accuracy\n",
    "    accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = accuracy_evaluator.evaluate(preds_model)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Precision\n",
    "    precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    precision = precision_evaluator.evaluate(preds_model)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "    # Recall\n",
    "    recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    recall = recall_evaluator.evaluate(preds_model)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # F1-score\n",
    "    f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1_score = f1_evaluator.evaluate(preds_model)\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "    auc_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "    auc_roc = auc_evaluator.evaluate(preds_model)\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "    print(\"-----------------\\n\")\n",
    "\n",
    "model_evaluator(rf_preds)"
   ],
   "id": "e55f2f628eefd66f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7779\n",
      "Precision: 0.7726\n",
      "Recall: 0.7779\n",
      "F1 Score: 0.7131\n",
      "AUC-ROC: 0.7141\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T04:46:46.130955Z",
     "start_time": "2025-03-19T04:46:45.665027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"models/rf_model\"\n",
    "\n",
    "rf_model.write().overwrite().save(model_path)\n",
    "print(f\"Model saved successfully at {model_path}!\")"
   ],
   "id": "2d813b0d242c6d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at models/rf_model!\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
